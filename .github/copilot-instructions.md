# Copilot Instructions

- **Purpose & scope**: Enzyme–reaction catalytic link prediction. Core code in `src/` uses Chemprop + PyTorch Lightning; Hydra drives configs in `configs/`.
- **Data prep workflow**: Run `python scripts/stage_data.py --config-name stage_data data=<data_cfg>`; outputs Parquet splits to `${filepaths.scratch}/${data.subdir_patt}`. `data/*.yaml` set dataset/toc/split strategy/embedding type; `filepaths/base.yaml` defines absolute paths (quest_data scratch/results, artifacts, clustering). Stage job chdirs to the sweep/run dir; override `hydra/launcher` to use Slurm (`quest_cpu`/`quest_gpu`).
- **Splitting logic**: `src/cross_validation.py` implements `random_split`, `stratified_sim_split` (cluster-aware via `artifacts/clustering/*.{clstr,json}`), and `sample_negatives`. Negative sampling is applied pre-split and often oversampled to 10x for train/val; group-aware splits for reaction or reaction-center when `group_by` supplied.
- **Data assembly**: `scripts/stage_data.py` builds train/val/test DataFrames with protein embeddings (loaded from `${filepaths.data}/${dataset}/${embed_type}/*.pt`), SMARTS strings, alt-mapped SMARTS, reaction centers; saves `train_val_{i}.parquet` and `test.parquet`. Alternate reaction-center negatives merge `_arc_unobserved_reactions.json` + `_arc_negative_samples.csv`.
- **Modeling (graph RC path)**: `configs/model/rc_agg.yaml` uses reaction-center featurizer (`rxn_rc`), `BondMessagePassing` message passing, `LastAggregation` (virtual-node last atom), predictor `DotSig` (reaction · protein sigmoid). `MPNNDimRed` in `src/model.py` extends Chemprop MPNN to concat reduced protein descriptors via `reduce_X_d`. Two-channel linear/FFN baselines combine reaction/protein embeddings then `DotSig`.
- **ClipZyme path**: `scripts/train_clipzyme.py` trains CLIP-style model from `src/clip.py` (pseudo-transition-state graph encoder + protein linear layer; optional BN). Hydra sweep over `data.split_idx=range(n_splits)`; set `data.split_idx=-1` for outer test, `-2` for full-data train. Negatives can be downsampled via `data.neg_multiple`; `training.pos_multiplier` boosts positive loss weight. CSV logs/checkpoints under `${filepaths.runs}/${exp}/${version}`.
- **Training configs**: `configs/training/base.yaml` lists metrics (F1/Precision/Recall/MCC/Accuracy/AUPRC/AUROC). `training/clipzyme.yaml` adds batch size and positive multiplier. `model/*.yaml` select aggregator, predictor, depths, hidden dims; `data/*.yaml` pick split strategy (homology/gsi/esm/rcmcs/drfp/random variants) and bounds.
- **Collation & loaders**: `src/data.py` defines `RxnRCDataset`/`MFPDataset`/`PretrainedFPDataset` with `collate_mfps`; uses Chemprop `SeededSampler` for deterministic shuffles. `clip_collate` in `src/clip.py` batches torch-geometric graphs plus protein tensors.
- **Loss/metrics**: `src/nn.py` provides `WeightedBCELoss`, `DotSig` predictor, attention and virtual-node aggregations. Many Lightning modules log via `self.log` with batch_size; masks handle NaNs in targets.
- **External deps**: Requires Chemprop, clipzyme (DMPNN), torch-geometric/torch-scatter, RDKit. Use `environment.yaml` or `setup.py` for editable install (`pip install -e .`).
- **Conventions/tips**:
  - Hydra config path is `../configs`; jobs set `job.chdir=True`, so resolve relative files via `cfg.filepaths.*`.
  - When adding a new split or sampler, wire it in `src/cross_validation.py` and mirror options in `configs/data/*.yaml`.
  - Paths in configs are absolute; if moving machines, update `filepaths/base.yaml` instead of per-script edits.
  - Outputs: stage data → `${scratch}/${subdir_patt}`; training → `${runs}/${exp}/${version}`; predictions saved alongside versions.
